import os
import tempfile
from typing import Dict, List, Any
from fastapi import UploadFile, HTTPException
from fastapi.responses import JSONResponse
from helpers.excel_parser import ExcelMaturityParser
from stores.llm.LLMProviderFactory import LLMProviderFactory
from helpers.config import get_settings

class MaturityController:
    def __init__(self):
        try:
            self.settings = get_settings()
            self.llm_factory = LLMProviderFactory()
        except Exception as e:
            print(f"ATTENTION: Configuration non disponible: {e}")
            self.settings = None
            self.llm_factory = None
    
    async def analyze_maturity_excel(self, file: UploadFile) -> Dict[str, Any]:
        """Analyse le fichier Excel de maturit√© et g√©n√®re des recommandations"""
        try:
            print(f"üîç D√©but de l'analyse du fichier: {file.filename}")
            # V√©rifier le type de fichier (Excel ou CSV)
            allowed_ext = ('.xlsx', '.xls', '.csv')
            if not file.filename.lower().endswith(allowed_ext):
                raise HTTPException(
                    status_code=400,
                    detail="Le fichier doit √™tre au format .xlsx, .xls ou .csv"
                )
            
            # Sauvegarder temporairement le fichier
            suffix = '.csv' if file.filename.lower().endswith('.csv') else '.xlsx'
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:
                content = await file.read()
                tmp_file.write(content)
                tmp_file_path = tmp_file.name
            
            try:
                # Parser le fichier Excel
                parser = ExcelMaturityParser(tmp_file_path)
                # Selon le besoin, on peut soit garder l'ancien mod√®le d'axes,
                # soit retourner un DataFrame normalis√© depuis le CSV.
                axes = parser.parse()
                records = parser.parse_records()
                
                if not axes:
                    raise HTTPException(
                        status_code=400,
                        detail="Aucun axe d'√©valuation trouv√© dans le fichier Excel"
                    )
                
                # Identifier les opportunit√©s d'am√©lioration
                opportunities = parser.get_improvement_opportunities()
                
                # G√©n√©rer des recommandations avec LLM
                recommendations = await self._generate_recommendations(opportunities)
                
                # Calculer le score global
                global_score = self._calculate_global_score(axes)
                
                # Pr√©parer la r√©ponse
                response = {
                    "global_score": global_score,
                    "total_axes": len(axes),
                    "axes_analysis": [
                        {
                            "name": axis.name,
                            "definition": axis.definition,
                            "average_score": round(axis.average_score, 2),
                            "max_score": 5.0,
                            "questions_count": len(axis.questions)
                        }
                        for axis in axes
                    ],
                    "flat_records": records,  # format tabulaire pr√™t pour le RAG
                    "improvement_opportunities": opportunities,
                    "recommendations": recommendations
                }
                
                return response
                
            finally:
                # Nettoyer le fichier temporaire
                if os.path.exists(tmp_file_path):
                    os.unlink(tmp_file_path)
                    
        except Exception as e:
            print(f"‚ùå Erreur dans analyze_maturity_excel: {str(e)}")
            print(f"‚ùå Type d'erreur: {type(e).__name__}")
            import traceback
            print(f"‚ùå Traceback: {traceback.format_exc()}")
            raise HTTPException(
                status_code=500,
                detail=f"Erreur lors de l'analyse du fichier: {str(e)}"
            )
    
    async def _generate_recommendations(self, opportunities: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """G√©n√®re des recommandations avec LLM pour chaque opportunit√©"""
        recommendations = {
            "short_term": [],  # 0-3 mois
            "medium_term": [],  # 3-12 mois
            "long_term": []  # 12+ mois
        }
        
        # Initialiser le LLM
        if self.llm_factory is None:
            print("ATTENTION: LLM non disponible, utilisation de recommandations par d√©faut")
            return self._generate_default_recommendations(opportunities)
        
        llm_provider = self.llm_factory.get_provider("cohere")
        
        for opportunity in opportunities:
            # Cr√©er le prompt pour le LLM
            prompt = self._create_recommendation_prompt(opportunity)
            
            try:
                # G√©n√©rer les recommandations avec le LLM
                llm_response = await llm_provider.generate_response(
                    prompt=prompt,
                    max_tokens=1000,
                    temperature=0.7
                )
                
                # Parser la r√©ponse du LLM
                parsed_recommendations = self._parse_llm_response(llm_response)
                
                # Organiser par √©ch√©ance
                for rec in parsed_recommendations:
                    timeline = rec.get("timeline", "medium_term")
                    if timeline in recommendations:
                        recommendations[timeline].append({
                            "axis_name": opportunity["axis_name"],
                            "question": opportunity["question"],
                            "current_situation": opportunity["current_response"],
                            "target_situation": opportunity["next_level_response"],
                            "recommendation": rec["action"],
                            "timeline": rec["timeline"],
                            "priority": rec.get("priority", "medium")
                        })
                        
            except Exception as e:
                print(f"Erreur LLM pour l'axe {opportunity['axis_name']}: {str(e)}")
                # Ajouter une recommandation par d√©faut
                recommendations["medium_term"].append({
                    "axis_name": opportunity["axis_name"],
                    "question": opportunity["question"],
                    "current_situation": opportunity["current_response"],
                    "target_situation": opportunity["next_level_response"],
                    "recommendation": f"Am√©liorer {opportunity['axis_name']} en passant de '{opportunity['current_response'][:50]}...' √† '{opportunity['next_level_response'][:50]}...'",
                    "timeline": "medium_term",
                    "priority": "medium"
                })
        
        return recommendations
    
    def _generate_default_recommendations(self, opportunities: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """G√©n√®re des recommandations par d√©faut sans LLM"""
        recommendations = {
            "short_term": [],
            "medium_term": [],
            "long_term": []
        }
        
        for opportunity in opportunities:
            # Recommandation par d√©faut
            default_rec = {
                "axis_name": opportunity["axis_name"],
                "question": opportunity["question"],
                "current_situation": opportunity["current_response"],
                "target_situation": opportunity["next_level_response"],
                "recommendation": f"Am√©liorer {opportunity['axis_name']} en passant de '{opportunity['current_response'][:50]}...' √† '{opportunity['next_level_response'][:50]}...'. Mettre en place un plan d'action progressif.",
                "timeline": "medium_term",
                "priority": "medium"
            }
            
            recommendations["medium_term"].append(default_rec)
        
        return recommendations
    
    def _create_recommendation_prompt(self, opportunity: Dict[str, Any]) -> str:
        """Cr√©e le prompt pour le LLM"""
        return f"""
Dans le contexte d'un audit de maturit√© DevSecOps, analysez cette situation :

**Axe d'√©valuation :** {opportunity['axis_name']}
**D√©finition de l'axe :** {opportunity['axis_definition']}

**Question :** {opportunity['question']}

**Situation actuelle :** {opportunity['current_response']} (Score: {opportunity['current_score']}/5)

**Objectif :** {opportunity['next_level_response']} (Score: {opportunity['next_level_score']}/5)

**Mission :** Fournir des recommandations concr√®tes et actionables pour permettre au client d'atteindre l'objectif au prochain audit.

R√©pondez au format JSON suivant :
{{
    "recommendations": [
        {{
            "action": "Action concr√®te √† mettre en ≈ìuvre",
            "timeline": "short_term|medium_term|long_term",
            "priority": "high|medium|low",
            "description": "Explication d√©taill√©e de l'action"
        }}
    ]
}}

Consid√©rez :
- Les contraintes techniques et organisationnelles
- Les d√©pendances entre les actions
- La faisabilit√© selon la taille de l'organisation
- Les bonnes pratiques DevSecOps
"""
    
    def _parse_llm_response(self, response: str) -> List[Dict[str, Any]]:
        """Parse la r√©ponse du LLM"""
        try:
            import json
            # Essayer de parser le JSON
            data = json.loads(response)
            return data.get("recommendations", [])
        except:
            # Si le parsing JSON √©choue, cr√©er une recommandation par d√©faut
            return [{
                "action": "Analyser et am√©liorer les processus actuels",
                "timeline": "medium_term",
                "priority": "medium",
                "description": response[:200] + "..." if len(response) > 200 else response
            }]
    
    def _calculate_global_score(self, axes: List) -> float:
        """Calcule le score global de maturit√©"""
        if not axes:
            return 0.0
        
        total_score = sum(axis.average_score for axis in axes)
        return round(total_score / len(axes), 2)
